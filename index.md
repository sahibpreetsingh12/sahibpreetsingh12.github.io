---
layout: home
title: "Sahibpreet Singh — LLM Systems Notes"
---

> Practical, measurement-driven notes on building and optimizing large language model systems.

### About
I focus on:
- **LLM inference** — latency/throughput, quantization, batching, KV cache engineering.
- **RAG** — retrieval quality, groundedness, answer evaluation.
- **Custom kernels** — Triton/CUDA for attention and fused ops.
- **Evaluation** — metrics and harnesses beyond raw accuracy.

**Start here**:
1. [Triton for the Impatient](./posts/)  
2. [A Practical RAG Evaluation Loop](./posts/)  
3. [LLM Throughput Engineering](./posts/)

